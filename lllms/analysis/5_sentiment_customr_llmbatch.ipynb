{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "696e888d",
      "metadata": {
        "id": "696e888d"
      },
      "source": [
        "\n",
        "# Customer Text Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcd8651e",
      "metadata": {
        "id": "fcd8651e"
      },
      "outputs": [],
      "source": [
        "#!pip install OpenAI\n",
        "#!pip install langchain\n",
        "#!pip install langchain_community\n",
        "#!pip install Cohere\n",
        "#!pip install langchain-openai langchain-cohere python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "UeBOnclk0E4H"
      },
      "id": "UeBOnclk0E4H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05db8157",
      "metadata": {
        "id": "05db8157"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os, json, re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import SystemMessage, HumanMessage\n",
        "\n",
        "# --------------------\n",
        "# CONFIG - EDIT HERE\n",
        "# --------------------\n",
        "CSV_PATH = r\"https://github.com/giridhar276/genai/raw/refs/heads/main/datasets/Bank_Customer_conversations.csv\"   # default to the generated CSV in this environment\n",
        "TEXT_COL = \"customer_text\"\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "TEMPERATURE = 0\n",
        "BATCH_SIZE = 40\n",
        "TIMEOUT = 60\n",
        "BINARY_OUTPUT = False\n",
        "\n",
        "OUTPUT_PATH = CSV_PATH.replace(\".csv\", \"_with_sentiment.csv\")\n",
        "\n",
        "# You must set OPENAI_API_KEY in your environment before running:\n",
        "openai_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "assert os.getenv(\"OPENAI_API_KEY\"), \"Please set OPENAI_API_KEY in your environment.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9e40f59",
      "metadata": {
        "id": "c9e40f59"
      },
      "outputs": [],
      "source": [
        "\n",
        "def strict_json_parse(s):\n",
        "    try:\n",
        "        return json.loads(s)\n",
        "    except Exception:\n",
        "        pass\n",
        "    m = re.search(r\"\\{.*\\}\", s, flags=re.DOTALL)\n",
        "    if not m:\n",
        "        return {\"label\": \"neutral\", \"confidence\": 0.33, \"reason\": \"fallback: parse error\"}\n",
        "    try:\n",
        "        return json.loads(m.group(0))\n",
        "    except Exception:\n",
        "        return {\"label\": \"neutral\", \"confidence\": 0.33, \"reason\": \"fallback: json error\"}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_label(label: str, binary: bool = False) -> str:\n",
        "    label = (label or \"\").strip().lower()\n",
        "    if label not in {\"positive\", \"neutral\", \"negative\"}:\n",
        "        label = \"neutral\"\n",
        "    if binary:\n",
        "        return \"positive\" if label == \"positive\" else \"negative\"\n",
        "    return label\n",
        "\n"
      ],
      "metadata": {
        "id": "_aaEnaIs22DB"
      },
      "id": "_aaEnaIs22DB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(x: str) -> str:\n",
        "    if not isinstance(x, str):\n",
        "        return \"\"\n",
        "    x = x.replace(\"\\r\", \" \").replace(\"\\n\", \" \").strip()\n",
        "    x = re.sub(r\"\\s+\", \" \", x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "4jZo_glS23Gf"
      },
      "id": "4jZo_glS23Gf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f039de",
      "metadata": {
        "id": "e2f039de"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df[\"customer_text\"] = df[TEXT_COL].astype(str).map(clean_text)\n",
        "df = df[df[TEXT_COL].str.len() > 0].copy()\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(\"Rows:\", len(df))\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "SYSTEM = \"\"\"You are a strict sentiment classifier for short customer utterances from bank call transcripts.\n",
        "Return ONLY a compact JSON object on a SINGLE LINE with keys:\n",
        "- \"label\": one of \"positive\", \"neutral\", \"negative\"\n",
        "- \"confidence\": a number in [0,1]\n",
        "- \"reason\": a brief rationale (<= 15 words)\n",
        "Judge tone + wording; ignore bank-specific facts. Prefer \"neutral\" if mixed.\n",
        "No extra text before/after JSON.\n",
        "\"\"\"\n",
        "\n",
        "USER_TMPL = '''Classify the sentiment of the CUSTOMER text below.\n",
        "Rules:\n",
        "- Output strictly ONE LINE of JSON only.\n",
        "- Labels: \"positive\" | \"neutral\" | \"negative\".\n",
        "- Keep \"reason\" short (<= 15 words).\n",
        "- Consider tone: polite, frustrated, aggressive, harsh.\n",
        "CUSTOMER:\n",
        "\"\"\" {text} \"\"\"'''\n",
        "\n"
      ],
      "metadata": {
        "id": "9iEwOQEJ07MZ"
      },
      "id": "9iEwOQEJ07MZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c21eec2",
      "metadata": {
        "id": "6c21eec2"
      },
      "outputs": [],
      "source": [
        "\n",
        "llm = ChatOpenAI(model=MODEL, temperature=TEMPERATURE, timeout=TIMEOUT)\n",
        "\n",
        "def build_messages(txt: str):\n",
        "    return [SystemMessage(content=SYSTEM), HumanMessage(content=USER_TMPL.format(text=txt))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1929e080",
      "metadata": {
        "id": "1929e080"
      },
      "outputs": [],
      "source": [
        "\n",
        "labels, confs, reasons = [], [], []\n",
        "\n",
        "def classify_batch(msgs):\n",
        "  results = llm.batch(msgs)\n",
        "  return [strict_json_parse(x.content) for x in results]\n",
        "\n",
        "buffer = []\n",
        "for i, txt in enumerate(df[TEXT_COL].tolist(), start=1):\n",
        "    buffer.append(build_messages(txt))\n",
        "    if len(buffer) >= BATCH_SIZE:\n",
        "        objs = classify_batch(buffer)\n",
        "        for o in objs:\n",
        "            labels.append(postprocess_label(o.get(\"label\"), BINARY_OUTPUT))\n",
        "            confs.append(float(o.get(\"confidence\", 0.5)))\n",
        "            reasons.append(o.get(\"reason\", \"\"))\n",
        "        buffer = []\n",
        "        if i % (BATCH_SIZE * 5) == 0:\n",
        "            print(f\"Processed {i}/{len(df)} rows...\")\n",
        "\n",
        "if buffer:\n",
        "    objs = classify_batch(buffer)\n",
        "    for o in objs:\n",
        "        labels.append(postprocess_label(o.get(\"label\"), BINARY_OUTPUT))\n",
        "        confs.append(float(o.get(\"confidence\", 0.5)))\n",
        "        reasons.append(o.get(\"reason\", \"\"))\n",
        "\n",
        "assert len(labels) == len(df), \"Batching length mismatch—check logic.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if df.empty:\n",
        "    raise RuntimeError(\"DataFrame is empty—upstream step failed (CSV read or LLM).\")\n",
        "\n",
        "df[\"sentiment_label\"] = labels\n",
        "df[\"sentiment_confidence\"] = confs\n",
        "df[\"sentiment_reason\"] = reasons\n"
      ],
      "metadata": {
        "id": "7F-qX2pV18Av"
      },
      "id": "7F-qX2pV18Av",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "bjaFHLfY2CPF"
      },
      "id": "bjaFHLfY2CPF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts = df[\"sentiment_label\"].value_counts().sort_index()\n",
        "print(\"\\nLabel counts:\\n\", counts)\n"
      ],
      "metadata": {
        "id": "J_6UWZng2CeG"
      },
      "id": "J_6UWZng2CeG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "counts.plot(kind=\"bar\")\n",
        "plt.title(\"Sentiment label distribution\")\n",
        "plt.xlabel(\"label\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9QB243d92ZUm"
      },
      "id": "9QB243d92ZUm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PPwbnCFj2Z0f"
      },
      "id": "PPwbnCFj2Z0f",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}